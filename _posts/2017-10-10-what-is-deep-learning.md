---
layout: post
title: "딥러닝이란 무엇인가?"
date: 2017-10-10 09:00:00 +0900
author: kilho_kim
categories: [machine-learning]
tags: [machine-learning, data-science]
comments: true
name: what-is-deep-learning
---

수아랩 리서치 블로그 두 번째 글의 주제는 '딥러닝이란 무엇인가?' 입니다. 오늘날의 AI(인공지능)를 가능하게 하는 기술이 '딥러닝'이라고들 하는데, 왜 수아랩 리서치 블로그에서 '머신러닝'부터 언급하고 '딥러닝'은 뒷전에 뒀는지 의아한 분들이 많으실 것으로 생각합니다. 이 글을 통해 그 궁금증을 풀어드리고자 합니다.

## 서론

요즘에 **딥러닝(Deep Learning)**이란 단어가 여기저기에서 많이 들려옵니다. 머신러닝(machine learning)과 왠지 느낌은 비슷한데, '딥'하다는 수식어가 붙어서 뭔가 좀 더 심오해(?) 보이기도 합니다. 

오늘날 딥러닝이라는 단어는 대부분 AI의 꼬리표처럼 등장하는 경우가 많습니다. 본래 딥러닝은 2016년 초까지는 아는 사람만 아는 단어였는데, 국내에서는 특히 2016년 3월 바둑 두는 기계인 '알파고(AlphaGo)'가 대한민국의 이세돌 9단을 바둑으로 압승하면서 널리 알려졌습니다. 세간에서는 AI의 괄목할 만한 발전을 보면서 딥러닝의 무궁무진한 가능성을 높게 보는 사람들이 늘어났고, 좀 더 상상력이 풍부하신 분들은 이를 보며 '인간이 기계 제국에 지배당할 날이 머지 않았다'는 우려까지 하시게 된 것 같습니다.

> "딥러닝 썼더니 바둑도 잘 두던데? 우리 비즈니스에도 딥러닝 적용하면 전부 대체 가능하겠네!!"

이러한 변화의 길목에서, 필자는 개인적으로 '딥러닝 만능주의'가 생겨나고 있다는 느낌을 지울 수 없습니다. 실제로 적지 않은 국가 혹은 기업의 의사결정권자들이, 딥러닝의 성공적인 적용 사례만을 보고 (위와 같은 뉘앙스로 말씀하시면서) 호기롭게 딥러닝을 자신들의 비즈니스에도 적용해보자는 주장을 하시는 것을 심심치 않게 보고 들어 왔습니다. 그러나, 현재의 딥러닝에는 엄연한 약점이 존재하며, 아직까지는 특정 부류 업무의 자동화를 위한 하나의 도구로 보아야 합당합니다. 

이번 글에서는 이러한 오해를 불식하고자, 딥러닝이란 기술이 본질적으로 무엇인지, 어떤 강점과 약점이 있는지, 어떠한 문제에 효과적으로 적용될 수 있는지 등을 중심으로 이야기해 보고자 합니다.


## 딥러닝 ⊂ 머신러닝

결론부터 얘기하자면, *딥러닝은 머신러닝의 세부 방법론들을 통칭하는 개념에 불과*합니다. 즉, 이론적으로 딥러닝은 머신러닝의 '부분집합'이라고 할 수 있으며, 사실 기존 머신러닝 이론에서 크게 새로울 것이 없습니다.

보다 자세한 설명을 위해서는 좀 더 수학적인 설명이 필요한데, 이에 앞서 <a href="http://research.sualab.com/machine-learning/2017/09/04/what-is-machine-learning.html" target="_blank">바로 이전 글</a>에서 살펴본 **머신러닝의 핵심 요소**를 다시 한 번 나열해보도록 하겠습니다.

### 머신러닝의 핵심 요소

- 데이터
- 러닝 모델 (+러닝 알고리즘)
- 요인 추출

엄밀히 말하면 요인 추출(feature extraction)은 *필수적인* 것은 아니나, 머신러닝의 성패를 크게 좌우하는 것이라 *핵심 요소* 리스트 상에 추가해 보았습니다. 머신러닝을 위해서는 데이터와 러닝 모델이 필요하며, 성공적인 학습을 위해서는 우선 데이터를 면밀히 조사하고 그 특징을 파악한 뒤, 이에 가장 적합한 러닝 모델을 잘 골라야 하며, 원 데이터를 그대로 사용하는 것보다는 효과적인 요인을 새로 정의하여, 이를 추출한 뒤 러닝 모델에 입력해주는 것이 좋다고 하였죠. 

### 퍼셉트론 - 선형 모델의 일반화

이전에 러닝 모델의 예시로 든, 가장 단순한 러닝 모델인 **선형 모델(linear model)**을 기억하시나요? 2개의 입력 변숫값으로 구성된 2차원 데이터 예시 $$(x_1, x_2)$$를 받아들여 하나의 출력 변숫값 $$f(x_1, x_2)$$을 출력하는 다음과 같은 함수를 예로 들었습니다:

\begin{equation}
f(x_1, x_2) = w_0 + w_1x_1 + w_2x_2
\end{equation}

저번 글에서의 '3개월 내 채무 이행 여부 예측 기계' 예시에서는, 어느 특정한 예시 $$(x_1, x_2$$에 대하여, 학습된 러닝 모델의 출력값 $$f(x_1, x_2)$$가 0보다 크면 'O'로, 작으면 'X'로 분류했던 바 있습니다.

{% include image.html name="what-is-machine-learning" file="age-to-salary-classify-sample-plot.png" description="3개월 내 채무 이행 여부 예측 결과 예시" class="medium-image" %}

선형 모델을 매번 위와 같은 수식으로 표현하면 한 번에 알아보기 불편하므로, 아래와 같이 좀 더 예쁜 그림으로 대신 표현하도록 하겠습니다.

{% include image.html name=page.name file="linear-model-diagram.svg" description="선형 모델의 도식화 예시" class="large-image" %}

위 그림을 보시면, 기본 뼈대에 $$w_0$$, $$w_1$$, $$w_2$$가 있고, 여기에 $$1$$, $$x_1$$, $$x_2$$가 각각 곱해진 후, 이들을 모두 합산한($$\sum$$) 결과를 그대로 출력하고 있습니다. 여기까지가 위에서 사용한 선형 모델인데, 일반적으로는 합산 결과에 **활성함수(activation function)**라는 모종의 함수 $$\sigma(\cdot)$$를 적용한 결과를 최종 출력값으로 대신 출력하는 경우가 많습니다. 여기에, d개의 입력 변숫값으로 구성된 *$$d$$차원* 데이터 예시 $$(x_1, x_2, ..., x_d)$$를 받아들이는 상황을 가정하면 아래와 같은 일반화된 그림을 표현할 수 있습니다.

{% include image.html name=page.name file="perceptron-diagram.svg" description="퍼셉트론" class="full-image" %}

일관성을 위해, 기존에 $$w_0$$이 등장하는 항에 $$x_0=1$$이 곱해진다고 가정하면, 입력 벡터 $$\boldsymbol{x}=(x_1, x_2, ..., x_d)$$를 받아들인 뒤 각 성분에 가중치를 곱하고, 그 결과를 모두 합산한 후, 활성함수 $$\sigma(\cdot)$$을 적용한다고 할 수 있습니다. 전체 과정을 수행하는 이 선형 모델을 하나의 함수 $$h(\cdot)$$로 나타낼 수 있으며, 이를 **퍼셉트론(perceptron)**이라고 부릅니다. 이 때, $$x_0=1$$까지 포함된 $$(d+1)$$차원 벡터를 받아들이므로 이를 편의 상 '$$(d+1)$$차원 퍼셉트론'으로 부르겠습니다. 당연히, 활성함수로 항등함수 $$\sigma(s)=s$$를 사용할 경우 이것은 위에서 살펴본 선형 모델이 될 것입니다. 

> 선형 모델은, 사실 퍼셉트론의 특수한 형태로 해석할 수 있습니다.

퍼셉트론의 모양을 가만히 살펴보면, 이는 신경계의 기본 단위인 <a href="https://ko.wikipedia.org/wiki/%EC%8B%A0%EA%B2%BD_%EC%84%B8%ED%8F%AC" target="_blank">**뉴런(neuron)**</a>과 그 모양이 매우 흡사합니다. 뉴런은 주변으로부터 자극을 받아들이는 돌기가 여러 개 뻗어 있으며, 이러한 자극들이 중심부의 핵으로 모여든 후 처리되고, 그 결과물을 다른 하나의 돌기를 통해 다른 곳으로 전달하도록 구성되어 있습니다. 이러한 유사성 때문에, 퍼셉트론을 흔히 인공 뉴런(artificial neuron) 혹은 줄여서 뉴런이라고도 부릅니다.

{% include image.html name=page.name file="neuron.png" description="뉴런의 구조" class="large-image" %}

### 인공신경망 - 퍼셉트론의 조합 및 확장의 결과

신경계에서의 뉴런들은 그 수가 엄청나게 많으며, 서로간에 매우 복잡한 구조로 얽히고설켜 하나의 거대한 망을 구성하는데, 이를 신경망(neural network)이라고 합니다. 머신러닝 과학자들은 신경계의 이러한 신경망 구조에 착안하여, 퍼셉트론을 하나의 빌딩 블록(building block)이라고 생각하고, 여러 개의 퍼셉트론을 아래 예시와 같이 연결한 **인공신경망(artificial neural network)**을 고안하였습니다.

{% include image.html name=page.name file="neural-network-detailed.svg" description="4개의 퍼셉트론 간의 2차원적 연결 예시" class="full-image" %}

위 그림에서 입력 벡터 $$\boldsymbol{x}=(x_1, x_2, ..., x_d)$$가 각각 상단, 중단, 하단에 위치한, 서로 다른 $$(d+1)$$차원 퍼셉트론의 입력값으로 들어갑니다(이를 각각 초록색, 붉은색, 보라색으로 표현했습니다). 각각의 퍼셉트론에서 가중합 및 합성함수를 거친 3개의 출력값이 $$x_0=1$$과 함께 4차원 퍼셉트론으로 입력됩니다. 4차원 퍼셉트론에서도 최종적으로 가중합 및 합성함수를 거치고, 최종적으로 1개의 값을 출력합니다. 

위와 같이 연결한 구조에서, 세 개의 **층(layer)**을 확인하실 수 있나요? 입력 벡터가 위치한 층을 첫 번째 층, 3개의 $$(d+1)$$차원 퍼셉트론이 나란히 붙어 출력한 값들이 위치하는 두 번째 층, 1개의 4차원 퍼셉트론이 출력한 값이 위치하는 세 번째 층으로 보시면 됩니다. 층 사이의 퍼셉트론들은 *낮은(앞쪽) 층*의 벡터를 각각 입력으로 받아 출력값을 내뱉고, 이는 *높은(뒷쪽) 층*의 벡터로 위치하는 구조를 확인할 수 있습니다. 

더 거대한 인공신경망 구조를 표현하기 위해, 지금부터는 하나의 퍼셉트론을 아래와 같이 좀 더 단순화시켜 표현해 보겠습니다. 그리고, 그림 상에서 입력값 또는 출력값을 나타내는 원형 부분을 **노드(node)**라고 표현할 것입니다.

{% include image.html name=page.name file="perceptron-simplified-diagram.svg" description="단순화된 퍼셉트론 구조" class="large-image" %}

그러면 총 3개의 층으로 구성되어 있으며, 첫 번째 층과 두 번째 층 사이에는 $$(d+1)$$차원 퍼셉트론이 $$H$$개, 두 번째 층과 세 번째 층 사이에는 $$(H+1)$$차원 퍼셉트론이 $$K$$개 있는 인공신경망을 아래와 같이 표현할 수 있습니다. *이 때, $$+1$$로 표시된 부분은 퍼셉트론이 위치하지 않으므로 주의하시길 바랍니다!*

{% include image.html name=page.name file="multilayer-perceptron.svg" description="다층 퍼셉트론의 일반적 구조" class="medium-image" %}

입력 벡터가 자리잡는 층을 **입력층(input layer)**, 최종 출력값이 자리잡는 층을 **출력층(output layer)**, 입력층과 출력층 사이에 위치하는 모든 층을 **은닉층(hidden layer)**이라고 합니다. 그림으로 표현할 때는 3개의 층을 그리나, 실제 인공신경망의 층 개수를 셀 때 입력층은 생략하는 것을 주의해야 합니다. 따라서 위 구조에서는 '총 *2개*의 층이 존재한다'고 부릅니다. 퍼셉트론을 기본 빌딩 블록으로 하여, 이런 패턴에 따라 2차원적으로 연결되어 구성되는 인공신경망의 일종을 특별히 **다층 퍼셉트론(MLP: multi-layer perceptron)**이라고 합니다.

이런 입력층-은닉층-출력층의 경우, 다층 퍼셉트론뿐만 아니라, 좀 있다 설명할 다양한 인공신경망 구조에서 공통적으로 존재하는 층입니다. 은닉층의 개수가 많아질수록 인공신경망이 *'깊어졌다(deep)'*고 부르며, 이렇게 *충분히 깊어진 인공신경망을 러닝 모델로 사용하는 머신러닝 패러다임*을 바로 **딥러닝(Deep Learning)**이라고 합니다. 그리고, 딥러닝을 위해 사용하는 충분히 깊은 인공신경망을 **심층 신경망(DNN: Deep neural network)**이라고 통칭합니다.

'그럼 은닉층 및 출력층이 몇 개 이상이 있어야 심층 신경망이냐?'는 의문이 생길 수 있는데, 일반적으로는 *은닉층+출력층이 2개 이상*이 되면 심층 신경망이라고 합니다. 예를 들어, 아래와 같이 8개 은닉층+출력층으로 구성된 다층 퍼셉트론은 심층 신경망입니다. 

{% include image.html name=page.name file="deep-neural-network-example.svg" description="심층 신경망 예시" class="full-image" %}

이제 여러분들은, *딥러닝은 머신러닝의 세부 방법론들에 불과하다*는 말의 의미를 이해하셨을 것이라고 생각합니다. 머신러닝의 큰 틀은 그대로 가져가되, 러닝 모델로 '충분히 깊은' 인공신경망을 사용하고, 이에 맞는 러닝 알고리즘을 사용하여 러닝 모델을 학습한 경우 '딥러닝을 했다'고 표현해도 크게 무리가 없습니다.


## 대표적인 딥러닝 모델

심층 신경망의 기본 단위는 퍼셉트론이라고 하였습니다. 바로 앞에서는 다층 퍼셉트론 구조를 소개하였는데, 복수 개의 퍼셉트론을 서로 어떻게 연결하느냐에 따라 그와는 다른 새로운 구조를 형성할수도 있습니다. 오늘날, 다루고자 하는 데이터의 속성에 따라 효과적으로 적용할 수 있는 특수한 구조의 심층 신경망이 여럿 발표되었는데, 그 중 현재 가장 많이 쓰는 것 3가지를 소개해 드리고자 합니다.

### 완전 연결 신경망

**완전 연결 신경망(fully-connected neural network)**은, 사실 앞서 소개했던 *다층 퍼셉트론을 지칭하는 또 다른 용어*입니다. 다만 여러 구조의 심층 신경망이 추가로 발표되면서 기존의 다층 퍼셉트론이라는 표현을 사용하기 다소 애매해졌고, 이에 따라 오늘날에는 완전 연결 신경망이라는 표현을 널리 사용하고 있습니다.

완전 연결 신경망은, 위의 *다층 퍼셉트론의 일반적 구조*에서와 같이 노드 간에 횡적/종적으로 2차원적 연결을 이룹니다. 이 때, 서로 같은 층에 위치한 노드 간에는 연결 관계가 존재하지 않으며, 바로 인접한 층에 위치한 노드들 간에만 연결 관계가 존재한다는 것이 핵심적인 특징입니다.

### 컨볼루션 신경망

완전 연결 신경망에서 하나의 층 내부만을 보면, 그 안에 위치한 노드들은 1차원적으로 세로 방향으로만 배치되어 있습니다. 만약 완전 연결 신경망의 하나의 층에 위치한 노드들이 2차원적으로 가로/세로 방향으로 동시에 배치되어 있다면 어떤 모습일까요? 각 층에 가로 $$w$$개, 세로 $$h$$개의 노드가 배치되어 있는 2층짜리 완전 연결 신경망을 생각해 봅시다.

{% include image.html name=page.name file="2d-deep-neural-network.svg" description="2차원적 완전 연결 신경망*<br><small>(*주의: 지면 관계상, 노드 간의 연결 관계에 대한 표현 및 $$+1$$ 노드는 생략하였습니다.)</small>" class="full-image" %}

위 그림과 같이 노드를 배치할 경우, 노드 간의 연결 개수가 막대하게 증가한다는 문제가 있습니다. 예를 들어, 아래 그림과 같이 입력층의 $$x_{11}$$ 노드에서 은닉층으로 이어지는 연결만 보더라도, 연결 하나 당 한 개의 가중치 값이 붙으므로 총 $$h \times w$$개의 가중치를 고려해야 합니다. 입력층에는 총 $$h \times w$$개의 노드가 존재하므로, 인접한 두 층 사이에만 총 $$h^2w^2$$개의 가중치가 필요합니다. 

{% include image.html name=page.name file="2d-deep-neural-network-connection-example.svg" description="2차원적 완전 연결 신경망에서 노드 하나에서 출발한 연결" class="medium-image" %}

연결 개수의 증가에 따라 가중치의 개수가 기하급수적으로 증가한다는 문제 때문에, 머신러닝 연구자들은 인접한 층 간의 모든 노드의 연결을 고려하는 대신, 크기가 작은 **필터(filter)**가 존재한다고 가정하고 아래 그림과 같이 필터가 겹쳐지는 부분에 대해서만 가중합 및 활성함수 연산을 하도록 하였습니다.

{% include image.html name=page.name file="convolutional-neural-network.svg" description="컨볼루션 신경망에서의 필터에 대한 연산" class="full-image" %}

하나의 필터는 그 크기만큼의 개수에 해당하는 가중치를 가지고 있으며, 이미지 상의 어느 특정한 특징을 요인으로 추출하여 출력할 수 있도록 가중치의 학습이 이루어집니다. 위 그림에서는 $$3 \times 3$$ 크기의 필터가 입력층의 가장 좌측 상단 $$3 \times 3$$ 영역에 적용되어, 이들 노드에 대한 가중합 및 활성함수 연산을 수행하고 그 출력값을 $$z_{22}$$에 저장하고 있습니다. 이렇게 필터는 원본 입력층 상에서 일정 간격만큼 횡적/종적으로 이동하면서 가중합 및 활성함수 연산을 수행하고, 그 출력값을 현재 필터의 위치에 놓습니다. 이러한 연산 방식은 컴퓨터 비전(computer vision) 분야에서 이미지에 대한 <a href="https://ko.wikipedia.org/wiki/%ED%95%A9%EC%84%B1%EA%B3%B1" target="_blank">컨볼루션(convolution)</a> 연산과 유사하여, 이러한 구조를 채택하는 심층 신경망을 특별히 **컨볼루션 신경망(CNN: convolutional neural network)**이라고 부르게 되었습니다. 컨볼루션 연산 결과 생성되는 은닉층을 특별히 *컨볼루션 층(convolutional layer)*이라고 부르며, 복수 개의 컨볼루션 층이 존재하는 신경망을 **심층 컨볼루션 신경망(DCNN: Deep convolutional neural network)**이라고 부릅니다.

이렇게 컨볼루션 층에서는 현재 필터가 위치한 노드에서, 그 필터가 커버하고 있는, *물리적으로 가까운* 곳에 위치한 노드만을 포괄하여 가중합을 계산하는데, 이는 가중치의 개수를 줄여주는 것 외의 또 다른 장점을 제공합니다. 하나의 필터로 하여금 *국부(local) 영역에 대한 특징에 집중*할 수 있도록 한다는 점이 그것입니다. 이러한 특성 때문에, 컨볼루션 필터는 2차원 영역 상의 물리적 거리가 중요한 판단 기준이 되는 이미지 등의 데이터에 대하여 효과적으로 적용될 수 있습니다. 

{% include image.html name=page.name file="tree-image-local-connectivity.svg" description="이미지에 대한 컨볼루션 필터의 국부 영역 특징에 대한 집중" class="full-image" %}

예를 들어, '이미지 상의 특정 영역 상에서의 수직 방향 경계 존재 가능성'이라는 요인을 추출하는 $$5 \times 5$$ 크기의 필터가 있다고 합시다. 이 필터가 현재 이미지 상의 $$(23,35)$$ 위치에 있을 경우, $$(21,33)$$에서 $$(25,37)$$ 사이에 있는 정사각형 영역 상에 위치한 픽셀(pixel)들의 값만을 참조합니다. 뜬금없이(?) 현재 위치에서 물리적으로 멀리 떨어져 있는, 이를테면, $$(86,79)$$에 위치한 픽셀의 값을 조사하지 않는다는 것이죠.

지금까지 서술한 내용에서는, 설명의 편의를 위해 하나의 필터만이 작동하는 것을 표현하였으나, 실제로는 컨볼루션 층 직전에 복수 개의 필터를 설치하고 각 필터의 컨볼루션 연산을 통해 복수 개의 출력 결과물이 생성되도록 합니다. 

{% include image.html name=page.name file="lenet-architecture.svg" description="컨볼루션 신경망의 최초 모델: LeNet" class="full-image" %}

컨볼루션 신경망은, 본래 2차원적 속성을 지니는 데이터에 효과적으로 적용할 수 있습니다. 위에서 보인 바와 같이, 이미지 데이터가 가장 대표적인 사례라고 할 수 있습니다. 실제로도 **이미지 인식(image recognition)** 분야에서 컨볼루션 신경망이 가장 활발하게 사용됩니다. 

(컨볼루션 신경망에 대한 보다 자세한 내용은, 추후에 또 다른 블로그 포스팅을 통해 다루도록 하겠습니다.)

### 순환 신경망

우리가 다루는 입력 데이터 중에서는, 특별히 선후 관계가 중요하게 취급되는 것들이 있습니다. <a href="https://ko.wikipedia.org/wiki/%EC%97%BC%EA%B8%B0%EC%84%9C%EC%97%B4" target="_blank">DNA 염기 서열</a>과 같은 것들이 대표적입니다. 하나의 예시의 길이가 가변적이며, 서두에 어떤 염기가 등장했는지에 따라 나중에 등장할 염기가 무엇이 될지 결정됩니다. 이와 같은 형태의 데이터를 **시퀀스(sequence)**라고 부릅니다.

{% include image.html name=page.name file="dna-sequencing.jpg" description="DNA 시퀀스" class="medium-image" %}

이러한 시퀀스 데이터의 길이 가변성과 선후 관계를 러닝 모델로 하여금 어떻게 학습할 수 있도록 할지에 대하여 머신러닝 과학자들은 고민을 지속해 왔습니다. 그러던 중, 아래의 두 가지 아이디어를 반영하여 새로운 구조의 완전 연결 신경망을 만들었습니다.

1. 데이터 시퀀스 상의 원소를 매 시점(timestep)마다 하나씩 입력한다.
2. 특정 시점에 나온 은닉층의 출력 벡터(이하 은닉 벡터)를, 시퀀스 상의 바로 다음 원소와 함께 입력한다.

{% include image.html name=page.name file="recurrent-neural-network.svg" description="순환 루프가 존재하는 완전 연결 신경망 구조" class="full-image" %}

데이터 시퀀스 상의 어느 시점 $$t$$의 원소 $$(x_1^{(t)}, x_2^{(t)}, ..., x_d^{(t)})$$를 완전 연결 신경망에 입력하는 과정에서, 바로 이전 시점 $$t-1$$의 은닉 벡터 $$(z_1^{(t-1)}, z_2^{(t-1)}, ..., z_H^{(t-1)})$$을 함께 입력하여 가중합 및 활성함수를 적용하는 구조입니다. 이렇게 은닉 벡터를 그 다음 시점으로 전달하는 이유는, 앞선 시점들에서의 입력 벡터 속 정보들이 현재 시점의 은닉 벡터에 누적되어 있다고 간주하기 때문입니다. 이러한 구조의 신경망을 **순환 신경망(RNN: recurrent neural network)**이라고 합니다. 순환 신경망은 실제 데이터 시퀀스에 대하여, 아래 그림과 같이 시점 순서대로 작동하게 됩니다. 

{% include image.html name=page.name file="recurrent-neural-network-example.svg" description="$$d$$차원 입력 벡터 시퀀스에 대한 순환 신경망의 작동 방식" class="full-image" %}

위 그림을 보면, 시점 $$1$$에서의 입력 벡터 $$(x_1^{(1)}, x_2^{(1)}, ..., x_d^{(1)})$$가 순환 신경망에 입력되었을 때의 은닉 벡터 $$(z_1^{(1)}, z_2^{(1)}, ..., z_H^{(1)})$$가 시점 $$2$$의 입력 벡터 $$(x_1^{(2)}, x_2^{(2)}, ..., x_d^{(2)})$$와 함께 입력되어 가중합 및 활성 함수를 통해 은닉층의 벡터 $$(z_1^{(2)}, z_2^{(2)}, ..., z_H^{(2)})$$를 결정합니다. 이러한 과정은 시점 $$2$$, 시점 $$3$$에서도 이어지며, 시점 $$T$$를 마지막으로 종료됩니다.

그리고 당연하게도, 순환 신경망 내에 복수 개의 은닉층을 배치할 경우, 이를 **심층 순환 신경망(DRNN: Deep recurrent neural network)**이라고 부릅니다. 

이렇게, 순환 신경망은 태생적으로 시퀀스 데이터에 대하여 잘 작동하도록 설계되어 있습니다. 오늘날 순환 신경망은 **자연어 처리(natural language processing)** 분야에서 특히 많이 적용되고 있습니다. 사람들이 사용하는 언어를 텍스트 시퀀스 형태의 데이터로 변환하였을 때, 이 또한 길이 가변성과 선후 관계의 특징을 지니기 때문입니다. 

(순환 신경망에 대한 보다 자세한 내용은, 추후에 또 다른 블로그 포스팅을 통해 다루도록 하겠습니다.)


## 딥러닝의 강점 

지금까지 딥러닝의 개념과 대표적인 딥러닝 모델에 대하여 알아보았습니다. 그러면 이제, 다들 딥러닝이 왜 그렇게들 좋다고 하는지 그 이유에 대해 파헤쳐보도록 하겠습니다. 

### 요인 표현 학습: 요인 추출의 자동화

<a href="http://research.sualab.com/machine-learning/2017/09/04/what-is-machine-learning.html" target="_blank">바로 이전 글</a>에서, 효과적인 요인(feature)을 정의하고 추출하는 것이 머신러닝의 성패에 지대한 영향을 미친다고 말씀드린 바 있습니다. 그리고 이는 해결하고자 하는 문제와 연관된 분야에 대한 풍부한 지식과 뛰어난 직관에 힘입은, 가히 예술에 가까운 작업이라고 하였습니다.

> 요인 추출은, 오랜 기간 갈고 닦은 장인 정신이 필요한 영역이었습니다. 그러나...

이는 딥러닝의 등장으로 서서히 깨지기 시작하였습니다. 바로 딥러닝 모델이 보유한 '**요인 표현 학습(feature representation learning)**' 능력 때문입니다. 기존의 선형 모델과 같이 *'얕은(shallow)'* 러닝 모델의 경우, 반드시 사람에 의해 사전에 정의된 요인 하에서 최적의 성능을 발휘하는 가중치를 찾아야만 했습니다. 반면 심층 신경망의 경우, 원본 데이터로부터 최적의 성능을 발휘하는 데 사용될 수 있는 요인 표현 방법을 스스로 학습하고, 이를 기반으로 최적의 성능을 발휘하는 가중치를 더욱 효과적으로 찾을 수 있습니다.

#### 요인 표현 학습 예시: 나무 여부 구별 기계

이해를 돕기 위해, 이전 글의 예시였던 \<나무 여부 구별 기계\>를 다시 한 번 가져왔습니다. 해상도가 (세로x가로) $$100 \times 150$$인 이미지에 대하여, 만약 다음 요인들을 정의하고 추출하여 사용한다면, 나무 여부를 *완벽하게* 구별할 수 있다고 가정해 보겠습니다(당연히 현실 상황과는 큰 괴리가 있으나, 어디까지나 이해를 돕기 위함입니다).

- 요인 $$f_1$$: 이미지 상단 중앙의 가로/세로 10픽셀 길이의 정사각형 영역 내의 평균 색상
- 요인 $$f_2$$: 이미지 하단 중앙의 가로/세로 10픽셀 길이의 정사각형 영역 내의 평균 색상

{% include image.html name=page.name file="tree-classifier-optimal-features.svg" description="나무 여부 구별 문제의 최적 요인" class="full-image" %}

좀 더 구체적으로, 나무 이미지 맨 위에서부터 j번째, 맨 왼쪽에서부터 i번째 위치한 픽셀의 RGB값을 각각 $$x_{(j,i,R)}, x_{(j,i,G)}, x_{(j,i,B)}$$라 하여 벡터로 변환해 주면, 이미지 상단 중앙의 10픽셀 길이 정사각형 영역 내 100개 픽셀, 하단 중앙의 10픽셀 길이 정사각형 영역 내 100개 픽셀, 두 요인 $$f_1$$, $$f_2$$의 계산 공식은 아래와 같이 됩니다.

{% include image.html name=page.name file="tree-image-vectorized.svg" description="나무 이미지의 입력 벡터화" class="full-image" %}

\begin{equation}
f_1 = \frac{1}{300}\big(x_{(21,71,R)}+x_{(21,71,G)}, ..., +x_{(30,80,B)}\big)
\end{equation}
\begin{equation}
f_2 = \frac{1}{300}\big(x_{(71,71,R)}+x_{(71,71,G)}, ..., +x_{(80,80,B)}\big)
\end{equation}

앞선 가정 하에서, 위 두 가지 요인 $$f_1$$, $$f_2$$는, 나무 여부를 구별하는 데 있어 *최적*의 요인입니다. 물론 실제로는 최적의 요인이 무엇인지는 오직 신(?)만이 알고 있으며, 사람은 단지 데이터에 대한 꾸준한 관찰을 통해 최적 요인의 '언저리'에만 접근할 수 있을 것이며, 노력을 많이 들이더라도 운이 많이 좋아야 최적 요인을 정확히 찾아낼 것입니다.

그런데, 나무 여부를 구별하는 데 있어 아래와 같은 구조의 심층 신경망을 러닝 모델로 사용한다고 가정해봅시다.

{% include image.html name=page.name file="tree-classifier-deep-neural-network.svg" description="나무 여부 구별 문제를 위한 심층 신경망 구조" class="large-image" %}

맨 처음 상황에서, 입력층과 은닉층 사이의 가중치들은 '적절히' 초기화되어 있습니다. 그런데, 요인 표현 방법을 스스로 학습할 수 있는 심층 신경망은, 학습이 진행될 수록 이 가중치들을 서서히 업데이트하면서 최종적으로는 아래와 같이 되도록 만듭니다.

{% include image.html name=page.name file="tree-classifier-deep-neural-network-optimized.svg" description="나무 여부 구별 심층 신경망의 최종 학습 결과" class="large-image" %}

그 결과, 심층 신경망 내 은닉층의 하나의 노드 $$z_1$$에는 요인 $$f_1$$이, 다른 하나의 노드 $$z_2$$에는 요인 $$f_2$$이 출력되는 결과를 가져왔습니다(가중합 공식을 떠올려 보면 확인하실 수 있습니다. 물론 이 때는 활성 함수가 항등 함수인 경우를 가정합니다). 심층 신경망이 스스로 최적의 요인 표현 방법을 찾아, 이를 *맨 마지막 은닉층*에 출력한 것이죠. 

이를 다른 관점에서 해석하면, 기존 $$45,000$$차원 공간에 존재하는 입력 벡터를, 2개의 요인 $$z_1$$, $$z_2$$로 표현되는 $$2$$차원 공간에 예쁘게 재배치한 것이라고 해석할 수 있습니다. 심층 신경망 내 출력층 직전에 위치한 퍼셉트론(혹은 선형 모델)은 이 새로운 2차원 벡터 $$(z_1, z_2)$$를 받아, 2차원 공간 상의 깔끔한 선형 경계를 찾게 되고, 이를 사용하여 최종적인 나무 여부 분류를 수행하게 되는 것입니다.

(물론 실제로는 심층 신경망도 '운이 좋아야' 최적 요인을 *정확히* 찾아내는 것이 사실입니다. 하지만, 적어도 최적 요인과 그 효과가 꽤 유사한, 차선의 요인은 사람보다 훨씬 잘 찾아냅니다.)

지금까지 딥러닝 모델이 요인 표현을 학습하는 가장 단순화된 사례를 보여드렸습니다. 물론 위 예시에서는 최적 요인의 개수가 2개이며 그 정체가 무엇인지 대충 알고 있다는, 다소 과격한 가정을 했습니다. 실제로는 이러한 사항을 전혀 모르기 때문에, 최적의 요인 표현 방법을 심층 신경망이 학습할 수 있도록 하고자 다양한 방법으로 심층 신경망의 구조를 변화시키며 실험을 거듭하는 것이 일반적입니다.

#### 깊을수록 풍부해진다

심층 신경망의 구조를 변화시키며 실험을 수행하던 머신러닝 과학자들은 놀라운 사실을 하나 발견하게 됩니다. 심층 신경망 내 은닉층의 개수를 증가시킬수록, 최적 요인 표현 방법을 더욱 효과적으로 학습한다는 것입니다. 

이는 특히 이미지 인식 분야에서 컨볼루션 신경망을 사용했을 때 더욱 가시적으로 드라마틱하게 드러납니다. 우리 주변의 다양한 사물 이미지를 분류할 수 있도록 학습된 심층 컨볼루션 신경망을 해부해 본 결과, 각 컨볼루션 층에 생성된 출력값이 아래 그림과 같은 양상을 보이는 것을 발견했습니다.

{% include image.html name=page.name file="convolutional-neural-network-representations.svg" description="컨볼루션 신경망의 추상화된 요인 표현 기능" class="large-image" %}

컨볼루션 신경망의 낮은 층에 해당할수록, 이미지 상의 각 세부 영역에서의 경계, 명암, 색상 변화 등 저수준(low-level)의 특징들을 요인 표현으로 포착하는 경향을 보였습니다. 이렇게 위치 별 저수준 요인은, 컨볼루션 신경망의 높은 층으로 올라가면서 서로 가까운 것들끼리 조합되고, 좀 더 넓은 영역에서 고수준(high-level)의 특징들을 요인 표현으로 포착하는 경향을 보였습니다. 

예를 들어, 컨볼루션 신경망은 위 그림에서의 자동차 이미지의 바퀴 근처에서 포착되는 저수준 요인들을 통해 *점*, *선*, *면* 등의 위치를 파악하고, 이것들을 조합한 고수준 요인을 통해 *원형의 사물*이 위치하며, 이것이 *자동차 바퀴*라는 것을 파악합니다. 컨볼루션 신경망의 점점 높은 층으로 올라갈수록 바퀴 외의 주변 사물들도 파악하게 되고, 마지막에는 파악한 내용들을 최종적으로 종합하여 이것이 자동차라는 것을 인식하게 되는 것입니다.

> 백지장도 맞들면 낫습니다. 특히 심층 신경망의 은닉층은, 맞들면 맞들수록 더-욱 낫습니다.

(그렇다고 무조건 은닉층을 많이 쌓기만 하는 것이 모든 문제 상황에 다 좋은 것은 아닙니다. 학습의 대상이 되는 데이터의 속성에 따라 쌓음의 정도를 달리 가져가야 합니다. 그 적정 수준 역시 실험을 통해 알아내야 합니다.)

### 요인 추출의 자동화가 가져온 변화

#### 어려운 머신러닝 문제들에 대한 해결 성능 극대화

딥러닝 모델의 요인 표현 학습 능력으로 인한 요인 추출의 자동화는, 머신러닝계에 거대한 변화를 가져오게 되었습니다. 가장 먼저, 기존에 '어려운 문제'라고 인식되어 오던 머신러닝 문제들에 대한 해결 성능이 극대화된 것을 들 수 있습니다. 이러한 변화가 가장 먼저 단적으로 드러난 분야가 이미지 인식 분야입니다.

이미지 인식 연구를 위한 대규모 프로젝트인 이미지넷(ImageNet) 측에서 개최하는 대회인 ILSVRC(ImageNet Large Scale Visual Recognition Challenge)에서는 매년 전 세계 각국에서 온 수많은 참가자들이 총 1,000개 카테고리의 사물들을 담고 있는 총 1,431,167장의 이미지 데이터셋을 대상으로 이미지 인식 문제 해결을 위한 대결을 펼쳐 왔습니다. 그러던 중, 2012년도 ILSVRC에서 토론토 대학 소속 대학원생 Alex Krizhevsky 외 2인이 심층 신경망을 러닝 모델로 사용하여 대회에 도전장을 던졌고, 그 전까지 20% 이상에 머물렀던 분류 오류율(error rate)을 10%대로 낮추는 쾌거를 거두며 우승하였습니다. 이를 통해 Alex Krizhevsky는 일약 스타덤에 올랐으며, 이는 향후 딥러닝의 부흥을 알리는 신호탄이 되었다고 해도 과언이 아닙니다.

{% include image.html name=page.name file="ilsvrc-error-rate-change.svg" description="ILSVRC에서의 연도에 따른 최저 오류율 기록" class="full-image" %}

이미지넷 측으로부터 최근까지 보고된 바에 따르면, 2015년도 우승자인 Microsoft Research의 Kaiming He 외 3인이 제안한 *ResNet*이라는 심층 신경망 모델이 분류 오류율 3.57%를 기록하였다고 하며, 이는 주최측에서 자체적으로 모집한 피실험자 집단에 대한 실험 수행 결과 얻은 *인간 분류 오류율*  5.1%을 하회하는 수치입니다. '드디어 기계가 사람을 뛰어넘었다'는 소식에 많은 사람들이 크게 흥분했고, 이는 딥러닝 광풍을 불러 일으키는 데 크게 기여하였습니다.

이미지 인식 분야뿐만 아니라, 음성 인식 및 자연어 처리, 바둑을 포함한 각종 게임 등에서도 딥러닝 모델은 인간의 수준에 필적하거나 이를 뛰어넘는 성능를 보여주고 있습니다.

> 그러나, 인간의 수준에 도달하는 결과를 만들어내기 위한 엄청난 전제 조건이 존재합니다. 그것은..

#### 손쉽고 신속한 커스터마이징

딥러닝 모델의 자동화된 요인 추출 능력은 산업계에도 매력적으로 다가왔고, 실제로 다양한 산업 내 각종 제품의 기능적 자동화에도 딥러닝 기술이 조금씩 적용되기 시작했습니다.

기존 규칙 기반 알고리즘(rule-based algorithm) 혹은 전통적인 머신러닝 알고리즘을 어느 특정한 제품의 자동화에 적용할 경우, 썩 괜찮은 규칙 혹은 요인을 정의하기 위해 방대한 사전 지식이 필요했으며, 완성된 규칙 혹은 요인을 검증하기 위해 수많은 관찰과 실험 등을 거쳐야만 했습니다. 그런데, 이런 고생을 들여 제품 기능의 자동화를 이루더라도, 제품을 둘러싼 환경이나 제품의 내재적 속성 등이 변화하게 되면 기존에 만들어 놓은 규칙 혹은 요인을 재사용하기 불가능해지는 경우가 많으며, 또 다시 같은 노력과 비용을 투입해야만 했습니다.

그런데 딥러닝 기술이 적용되면서, 이러한 수고를 대폭 줄일 수 있게 되었습니다. 딥러닝 모델만이 가지는 자동화된 요인 추출 능력으로 인해, 제품의 자동화를 구현하는 데 필요한 최적의 규칙 혹은 요인이 무엇일지를 알아서 빠르게 찾아낼 수 있기 때문에, 이에 대해 사람이 고민해야 할 필요가 상당 부분 줄어들었습니다. 즉, 한 종류의 딥러닝 모델만 가지고도 다양한 제품에 대하여 손쉽고 신속하게 *커스터마이징(customizing)*을 수행하는 것이 가능해졌다는 것입니다.


## 딥러닝의 약점

그럼 이제 비로소 장인 정신이 필요 없어진 시대가 온 것일까요? 혹은, 인간의 노동력이 필요 없어진 시대가 온 것일까요?  그렇지는 않습니다. 딥러닝을 적용하고자 할 시, 아직은 치명적인 약점이 몇 가지 존재합니다.


### 많은 데이터 요구량

딥러닝 모델은 가히 데이터를 먹는 괴물(?)입니다. 딥러닝 모델의 성능이 '인간의 수준'에 도달하려면, 대단히 많은 양의 데이터를 필요로 합니다. 

앞쪽에서, 이미지넷의 이미지 인식 대회인 ILSVRC에서 2015년도에 나온 *ResNet*이라는 심층 신경망의 분류 오류율이 3.57%이라는 소식을 전해드렸습니다. 딥러닝에 대한 기대가 크신 분들의 경우, 십중팔구 아래와 같이 반응하실 것이라고 예상합니다.

> 와, 3.57%? 인간의 5.1%보다 한참 낮은 걸 보니 인간을 능가했네!
  
그런데 사실은 그 부분만을 볼 것이 아니라, 'ILSVRC에서 무려 *1,431,167장*의 이미지로 구성된 데이터셋을 제공하였다'는 부분에 *특히* 더 주목해야 합니다(따로 명시해놓지는 않았지만, '적절하게 정제된' 이미지를 의미합니다). 1,000개 카테고리의 사물을 인간 수준으로 분류하는 데 있어, 1개 카테고리 당 대략 *1,431장*의 이미지를 필요로 하였다고 해석할 수 있습니다. 여러분이 유년 시절에 다양한 사물의 개념에 대해 파악하던 시절을 떠올려보면, 이를테면, '나무'라는 사물의 개념을 파악하기 위해 무려 1,431장의 그림들을 보진 않았을 것이라고 감히 확신합니다('나무 전집' 따위의 책도, 그 안에 1,431장의 나무들을 담고 있진 않을 것 같습니다).

{% include image.html name=page.name file="ilsvrc-images-example.jpg" description="ILSVRC에서 제공된 이미지의 일부 예시" class="full-image" %}

ILSVRC에서 사용되는 데이터셋을 만든 이미지넷은, 미국 내 주요 대학의 컴퓨터과학과 교수진들을 위시하여 준비된 대규모 프로젝트입니다. 이들은 웹 크롤링(web crawling)을 통해 원본 이미지들을 수집하고, 크라우드소싱(crowdsourcing)을 통해 각 이미지에 어떤 사물이 담겨 있는지에 대한 레이블링(labeling)을 공개적으로 수행하였다고 합니다. 이러한 작업을 상당 부분 자동화하였음에도 불구하고, <a href="https://arxiv.org/pdf/1409.0575.pdf" target="_blank">ILSVRC 측에서 발표한 논문</a>을 보면 이 거대한 데이터셋을 준비하는 과정에서의 고충이 구구절절하게(?) 드러나 있습니다.

> 어쩌면, 쟁쟁한 교수진들이 선두에 섰기 때문에 가능한 프로젝트였는지도 모르겠습니다. 그 당시에 휘하에 있었을 대학원생들에게 진심어린 경의를 표합니다..

이렇게 딥러닝 모델은 데이터의 요구량이 매우 많기 때문에, 아직은 모든 종류의 산업에 적용되기에는 어려움이 많습니다. 산업 현장에서 나오는 데이터 자체도 '돈'이며, 이를 필요에 따라 적절하게 정제하는 과정에서도 적지 않은 비용이 요구되기 때문입니다. 이러한 문제를 해결하고자, 주요 학계와 산업계에서는 최소한의 데이터를 가지고 준수한 성능을 발휘하는 딥러닝 기술을 개발하고자 총력을 기울이고 있으나, 아직 대부분은 꽃길보다는 흙길을 걷고 있는 실정입니다. 

### 느린 속도와 높은 요구 사양

딥러닝 모델이 실제 산업에 적용되는 상황에서 발목을 잡게 되는 또 다른 부분은, 바로 느린 속도와 높은 요구 사양입니다. 이는 특히 저희 수아랩이 집중하고 있는 제조업 분야에서의 중요한 선결 과제로 손꼽힙니다.

{% include image.html name=page.name file="production-line-example.png" description="제조업 생산 라인의 모습" class="medium-image" %}

제조업 공장에서의 생산 라인을 직접 견학해 보신 분은 아시겠지만, 생산 라인이 흘러가는 속도는 여러분이 일반적으로 예상하시는 것보다 훨씬 빠릅니다. 만약 갓 생산된 제품의 외형을 실시간으로 촬영한 이미지를 사용하여, 제품에 결함이 존재하는지를 검사하는 장비를 제작하고자 한다면, 검사 속도가 컨베이어 벨트의 속도보다는 반드시 빨라야 합니다. 

그런데, 딥러닝 모델의 경우 특유의 거대한 구조 때문에 그 안에 많은 수의 가중치를 포함하고 있으며, 그만큼 가중합 및 활성 함수 연산을 더 많이 수행해야 합니다. 그래서, 딥러닝 모델에 대한 특별한 조치 없이, 일반적인 이미지 인식 분야에서 사용되는 딥러닝 모델을 결함 검사에 그대로 갖다 쓸 경우 검사 속도가 요구 수준에 도달하지 못하는 상황이 발생하게 됩니다.

이러한 문제를 해결하기 위한 가장 직관적인 방법은 결함 검사에 사용하는 컴퓨터의 사양을 업그레이드하는 것인데, 이 과정에서 추가적인 비용이 소요될 수밖에 없습니다. 그러나 대부분의 공장에서는 이러한 부분에서의 추가적인 비용 지출을 꺼려하는 것이 보통입니다.

이 또한, 주요 학계와 산업계에서 해결하고자 하는 주요 문제 중 하나입니다. 이들의 연구는 기존 모델을 가능한 한 많이 경량화하여, 기존의 성능을 저해하지 않도록 하면서 최소한의 컴퓨팅 리소스를 가지고 최대한 빠른 속도로 예측을 수행할 수 있도록 하는 데 초점이 맞춰져 있습니다.


## 결론

딥러닝이란, 본질적으로 머신러닝의 세부 방법론을 통칭하는 개념에 불과합니다. 즉, '퍼셉트론을 빌딩 블록으로 하여 쌓아올린, 심층 신경망을 러닝 모델로 사용하는 머신러닝 방법론'이 바로 딥러닝입니다. 오늘날 주로 사용되는 대표적인 딥러닝 모델에는 크게 완전 연결 신경망, 컨볼루션 신경망, 순환 신경망이 있으며, 각각이 주로 사용되는 분야가 뚜렷하게 정해져 있는 편입니다. 

딥러닝의 최대 강점은, 요인 표현을 스스로 학습할 수 있는 능력이며, 이로 인해 요인 추출을 자동으로 수행한다는 것입니다. 이러한 경향은 심층 신경망의 은닉층의 개수를 늘릴수록(더 깊게 만들수록) 극대화됩니다. 그 결과, 기존에 어렵게 느껴졌던 머신러닝 문제들에 대한 해결 성능이 비약적으로 상승하였으며, 산업 속 제품의 자동화에 있어서 손쉽고 신속한 커스터마이징을 가능하게 하였습니다. 그러나, 딥러닝 모델은 충분한 학습을 위해 매우 많은 양의 데이터를 요구하고, 그 거대한 몸집 때문에 속도가 느린 편이며, 그와 동시에 높은 수준의 컴퓨팅 리소스를 요구합니다.

> 이러한 문제들 때문에, 다행스럽게도, 아직 인간이 기계 제국에 지배당할 날은 한참 멀었습니다.

한편 본 글에서는, 저번에도 그랬듯, 딥러닝 모델의 러닝 알고리즘에 대해서는 전혀 설명하지 않았습니다. 이를 이해하고자 하는 시점부터, 비로소 프로그래밍, 미적분학, 선형대수학, 통계학 등에 대한 기본적인 지식이 필요하기 때문입니다. 비록 딥러닝 모델의 러닝 알고리즘을 자세히 살펴보지 못하셨더라도, 본 글을 통해서 딥러닝의 개념과 종류, 강점/약점 등을 파악하셨다면, 추후에 딥러닝 혹은 AI 등과 관련된 내용을 추가로 받아들이고 이해하시는 데 충분히 도움이 될 것이라고 생각합니다.

저희 수아랩에서는, 위에서 언급한 실제 산업 현장에서의 현실적인 어려움에도 불구하고, 딥러닝이 제조업 분야에 적용되었을 때의 파급 효과를 여전히 높게 보고 있으며, 이러한 어려움을 극복하고자 다양한 연구를 진행하고 있습니다. \*향후 글에서는, 수아랩에서 진행하고 있는 딥러닝 관련 연구 주제들에 대하여 하나씩 소개해 드리도록 하겠습니다.


## References

- 뉴런의 구조
  - <a href="https://en.wikipedia.org/wiki/Neuron" target="_blank">"Neuron." Wikipedia: The Free Encyclopedia. Wikimedia Foundation, Inc. 22 July 2004. Web. 10 October 2004., https://en.wikipedia.org/wiki/Neuron</a>
- 컨볼루션 신경망의 최초 모델: LeNet
  - <a href="http://www.dengfanxin.cn/wp-content/uploads/2016/03/1998Lecun.pdf" target="_blank">LeCun, Yann, et al. "Gradient-based learning applied to document recognition." Proceedings of the IEEE 86.11 (1998): 2278-2324.</a>
- DNA 시퀀스
  - <a href="http://www.sciencemag.org/news/2016/11/rise-digital-dna-raises-biopiracy-fears" target="_blank">Kelly Servick, "Rise of digital DNA raises biopiracy fears." Science, http://www.sciencemag.org/news/2016/11/rise-digital-dna-raises-biopiracy-fears. Accessed 10 October 2017.</a>
- 컨볼루션 신경망의 추상화된 요인 표현 기능
  - <a href="http://www.cs.nyu.edu/~yann/talks/lecun-ranzato-icml2013.pdf" target="_blank">LeCun, Yann, et al. "Deep Learning Tutorial." ICML, Atlanta. 16 June 2013.</a>
- ILSVRC에서의 연도에 따른 최저 오류율 기록
  - <a href="http://cs231n.stanford.edu/slides/2017/cs231n_2017_lecture1.pdf" target="_blank">Li, Fei-Fei, et al. "Convolutional Neural Networks for Visual Recognition." Stanford University, iStanford. 4 April 2017.</a>
- ILSVRC에서 제공된 이미지의 일부 예시
  - <a href="http://karpathy.github.io/2014/09/02/what-i-learned-from-competing-against-a-convnet-on-imagenet/" target="_blank">Andrej Karpathy, "What I learned from competing against a ConvNet on ImageNet." Andrej Karpathy blog, http://karpathy.github.io/2014/09/02/what-i-learned-from-competing-against-a-convnet-on-imagenet. Accessehttp://karpathy.github.io/2014/09/02/what-i-learned-from-competing-against-a-convnet-on-imagenet. Accessed 10 October 2017.</a>
- 이미지넷 ILSVRC 측에서 발표한 논문
  - <a href="https://arxiv.org/pdf/1409.0575.pdf" target="_blank">Russakovsky, Olga, et al. "Imagenet large scale visual recognition challenge." International Journal of Computer Vision 115.3 (2015): 211-252.</a>
- 제조업 생산 라인의 모습
  - 수아랩, "4차산업혁명 시대와 딥러닝 스마트팩토리 솔루션", Smart Connected World 2017. 판교 스타트업캠퍼스, Seongnam, 18 August 2017. Lecture.
